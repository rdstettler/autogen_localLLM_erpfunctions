{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call local ERP System using local LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requisites\n",
    "\n",
    "Install required modules if not already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyautogen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, I added the variable. If True, it will call the localhost, if False, it will call OpenAI's model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_local = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules and define the configurations for the models.\n",
    "The local files should look eiher\n",
    "\n",
    "for OpenAI\n",
    "[\n",
    "    {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"api_key\": \"sk-...\"\n",
    "    }\n",
    "]\n",
    "\n",
    "or for localhost\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"model\": \"mistral-7b-instruct-v0.2.Q4_K_M\",\n",
    "        \"api_key\": \"sk-11111111111111111111111111111111\",\n",
    "        \"base_url\": \"http://localhost:8000/v1\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "file = \"OAI_CONFIG_LIST.json\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "if use_local:\n",
    "    file = \"OAI_CONFIG_LIST_LOCAL.json\"\n",
    "    model = \"mistral-7b-instruct-v0.2.Q4_K_M\"\n",
    "\n",
    "config_list = autogen.config_list_from_json(\n",
    "    file,\n",
    "    filter_dict={\n",
    "        \"model\": [model]\n",
    "    }\n",
    ")\n",
    "\n",
    "llm_config = {\n",
    "    \"timeout\": 600,\n",
    "    \"seed\": 42,\n",
    "    \"config_list\": config_list,\n",
    "    \"temperature\": 0.5,\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_description_of_workcenter\",\n",
    "            \"description\": \"Get the ERP description of a given workcenter id\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"workcenter_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The ERP workcenter id\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"workcenter_id\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"get_current_orderdata_for_workcenter\",\n",
    "            \"description\": \"Get the ERP order for a given workcenter\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"workcenter_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The ERP workcenter id\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"workcenter_id\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the functions (I first tried to have them in a separate file and import them, that didn't work either, only with OpenAI's API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verpackungsanlage 441\n",
      "{'machineId': 'M1002976', 'localName': 'Montagelinie A55', 'workcenter': '511V0B01', 'location': 'Factory A1', 'doesSendToERP': False, 'hasCounterData': False, 'material': '3232975117A', 'order': '1234567', 'confirmation': '1827398172'}\n"
     ]
    }
   ],
   "source": [
    "from skills import *\n",
    "print(get_description_of_workcenter('511V0001'))\n",
    "print(get_current_orderdata_for_workcenter('511V0001'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define agents\n",
    "\n",
    "### User Proxy\n",
    "Simulation of user, can execute code\n",
    "\n",
    "### Assistant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_system_message = \"You're a helpful asssistant.\"\n",
    "\n",
    "if use_local: \n",
    "    assistant_system_message = \"\"\"PROVIDE USEFUL PYTHON CODE INCORPORATING THE LOCALLY AVAILABLE FUNCTIONS FOR ERP REQUESTS. You are being given the following python functions with description. Assume the functions available to the user, without having to import anything\n",
    "    function name: get_description_of_workcenter\n",
    "    argument (string, use quotes): workcenter_id\n",
    "    description: Get the description of a given workcenter id\n",
    "\n",
    "    function name: get_current_orderdata_for_workcenter\n",
    "    argument (string, use quotes): workcenter_id\n",
    "    description: Get the order for a given workcenter\n",
    "\n",
    "    Use those functions when answering. \n",
    "    \"\"\"\n",
    "\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name='assistant',\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and \"terminate\" in x.get(\"content\", \"\").lower(),\n",
    "    system_message=assistant_system_message,\n",
    ")\n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name='user_proxy',\n",
    "    human_input_mode='NEVER',\n",
    "    max_consecutive_auto_reply=4,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\") and \"terminate\" in x.get(\"content\", \"\").lower(),\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False\n",
    "    },\n",
    "    llm_config=llm_config,\n",
    "    system_message=\"\"\"You are a local ERP API assistant, you know the functions get_description_of_workcenter and get_current_orderdata_for_workcenter.\n",
    "    If the task was answered to full satisfaction, summarize with repeating the task and add the result and end the answer with the word TERMINATE.\"\"\",\n",
    ")\n",
    "\n",
    "user_proxy.register_function(\n",
    "    function_map={\n",
    "        \"get_description_of_workcenter\": get_description_of_workcenter,\n",
    "        \"get_current_orderdata_for_workcenter\": get_current_orderdata_for_workcenter\n",
    "    }\n",
    ")\n",
    "assistant.register_function(\n",
    "    function_map={\n",
    "        \"get_description_of_workcenter\": get_description_of_workcenter,\n",
    "        \"get_current_orderdata_for_workcenter\": get_current_orderdata_for_workcenter\n",
    "    }\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it doesn't work with import skills, try to define it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    @user_proxy.register_for_execution()\n",
    "    @assistant.register_for_llm(description='Userfull for getting the name of the workcenter')\n",
    "    def get_description_of_workcenter(workcenter_id: str) -> str:\n",
    "        \"\"\"\n",
    "        Calls the ERP api and requests the description of a ERP Workcenter Id. This is a helper function.\n",
    "\n",
    "        Args:\n",
    "            query (str): The ERP workcenter id.\n",
    "\n",
    "        Returns:\n",
    "            string: The description of the ERP workcenter id\n",
    "\n",
    "        Example:\n",
    "            >>> results = get_description_of_workcenter(\"10110101\")\n",
    "            >>> print(results) # prints e.g. \"Waschanlage 1234\"\n",
    "        \"\"\"\n",
    "        return random.choice([\"Stanzanlage 3.12\", \"Montage M1233\", \"Verpackungsanlage 441\", \"Montagelinie A55\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "What name does workcenter 511V0001 have? \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "\u001b[32m***** Suggested function Call: get_description_of_workcenter *****\u001b[0m\n",
      "Arguments: \n",
      "{\n",
      "  \"workcenter_id\": \"511V0001\"\n",
      "}\n",
      "\u001b[32m******************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_description_of_workcenter...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "\u001b[32m***** Response from calling function \"get_description_of_workcenter\" *****\u001b[0m\n",
      "Verpackungsanlage 441\n",
      "\u001b[32m**************************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "The workcenter 511V0001 is named \"Verpackungsanlage 441\".\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "The workcenter 511V0001 is named \"Verpackungsanlage 441\". TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_proxy.initiate_chat(\n",
    "    assistant,\n",
    "    message=\"What name does workcenter 511V0001 have? \"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
